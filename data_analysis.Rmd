---
title: "data_analysis"
author: "Antoinette Fang"
date: "2024-07-21"
output: html_document
---


```{r load packages}
library(tidyverse)
library(caret)
library(writexl)
library(dplyr)
library(furrr)

# Set up parallel processing
plan(multisession)
```

```{r setup}
# Import and prepare data
data <- read.csv("./clean data/cleaned_strata_senior.csv")
disease_frequencies <- read.csv("./frequency tables/disease_frequencies_senior.csv")

# Sort data by unique identifier
data <- data %>% arrange(dog_id)

# Separate predictors
predictors <- data %>%
  dplyr::select(
    dd_age_years, dd_weight_lbs, dd_breed_pure_or_mixed,
    recode.sex_2, recode.sex_3, recode.sex_4
  )

# Separate response variables
responses <- data %>%
  dplyr::select(matches("^(condition_|hs_cancer_types)"))
```

```{r helper functions}
# Function to get numerical code for cancer types
get_cancer_code <- function(cancer_type) {
  if (is.character(cancer_type) && startsWith(cancer_type, "hs_cancer_types_")) {
    cancer_name <- sub("hs_cancer_types_", "", cancer_type)
    code <- disease_frequencies %>%
      filter(Disease.Name == cancer_name) %>%
      pull(Numerical.Codes)
    return(if(length(code) == 0) cancer_type else as.numeric(code))
  }
  return(cancer_type)
}

# Function to clean disease names
clean_disease_name <- function(name) {
  if(startsWith(name, "condition_")) {
    return(sub("^condition_", "", name))
  } else if(startsWith(name, "hs_cancer_types_")) {
    code <- disease_frequencies %>%
      filter(Code.from.DAP.data == name) %>%
      pull(Numerical.Codes)
    return(if(length(code) == 0) name else as.character(code))
  }
  return(name)
}

# Function to calculate jacobian matrix for logistic regression
calculate_jacobian <- function(predictors, coefficients) {
  predictors <- as.matrix(predictors)
  coefficients <- as.numeric(coefficients)
  predictors_with_intercept <- cbind(1, predictors)
  linear_predictor <- predictors_with_intercept %*% coefficients
  deriv <- as.vector(exp(-linear_predictor) / (1 + exp(-linear_predictor))^2)
  jacobian <- matrix(deriv, nrow = 1) %*% predictors_with_intercept / nrow(predictors)
  return(jacobian)
}

calculate_delta_variance <- function(predictors, coefficients, vcov_matrix) {
  # Convert inputs to appropriate formats
  predictors <- as.matrix(predictors)
  coefficients <- as.numeric(coefficients)
  vcov_matrix <- as.matrix(vcov_matrix)
  # Add intercept column
  predictors_with_intercept <- cbind(1, predictors)
  # Calculate linear predictor
  linear_predictor <- predictors_with_intercept %*% coefficients
  # Calculate derivative for each observation
  deriv <- exp(-linear_predictor) / (1 + exp(-linear_predictor))^2
  # Calculate individual variances
  variances <- sapply(1:nrow(predictors), function(i) {
    # Calculate jacobian for this observation
    jacobian <- matrix(deriv[i] * predictors_with_intercept[i,], nrow = 1)
    # Calculate variance for this observation
    var <- jacobian %*% vcov_matrix %*% t(jacobian)
    return(as.numeric(var))
  })
  
  return(variances)
}

# Create standardized disease lookup table
disease_lookup <- disease_frequencies %>%
  mutate(
    code = case_when(
      Disease.Category == "Cancer" ~ paste0("hs_cancer_types_", Disease.Name),
      TRUE ~ paste0("condition_", Numerical.Codes)
    )
  ) %>%
  dplyr::select(code, Disease.Name)

# Fit logistic regression models
fit_logistic <- function(response, predictors) {
  model <- glm(response ~ ., data = predictors, family = binomial(link = "logit"))
  coef_summary <- summary(model)$coefficients
  tibble(
    Term = rownames(coef_summary),
    Coefficient = coef_summary[, "Estimate"],
    P_value = coef_summary[, "Pr(>|z|)"]
  )
}
```

```{r LRM for each disease}
# Fit models
model_results <- future_map(responses, ~fit_logistic(.x, predictors))

# Combine and format results
coef_pvalue_df <- bind_rows(
  imap(model_results, ~mutate(.x, Disease = .y))
)
coef_pvalue_wide <- coef_pvalue_df %>%
  pivot_wider(
    id_cols = Disease,
    names_from = Term,
    values_from = c(Coefficient, P_value),
    names_glue = "{Term}_{.value}"
  )
coef_pvalue_wide_named <- coef_pvalue_wide %>%
  left_join(disease_lookup, by = c("Disease" = "code")) %>%
  relocate(Disease.Name, .after = Disease)

write.csv(coef_pvalue_wide_named, 
          "./model coefficients/coef_and_pvalues_senior.csv", 
          row.names = FALSE)

# Extract coefficients
coef_df <- coef_pvalue_wide %>%
  dplyr::select(Disease, ends_with("_Coefficient")) %>%
  rename_with(~str_remove(., "_Coefficient"), ends_with("_Coefficient"))

coef_df_named <- coef_df %>%
  left_join(disease_lookup, by = c("Disease" = "code")) %>%
  relocate(Disease.Name, .after = Disease)

write.csv(coef_df_named, 
          "./model coefficients/coef_only_senior.csv", 
          row.names = FALSE)
```

```{r calculate individual probabilities}
# Calculate risks and variances
risk_scores <- future_map(names(responses), function(disease) {
  response <- responses[[disease]]
  model <- glm(response ~ ., data = predictors, family = binomial(link = "logit"))
  
  linear_pred <- predict(model, type = "link")
  probabilities <- 1 / (1 + exp(-linear_pred))
  
  actual_count <- sum(response)
  scaling_factor <- actual_count / sum(probabilities)
  normalized_probs <- probabilities * scaling_factor
  
  variances <- calculate_delta_variance(predictors, coef(model), vcov(model))
  adjusted_variances <- variances * scaling_factor^2
  
  list(
    probabilities = normalized_probs,
    variance = adjusted_variances
  )
})

# Extract probabilities and variances using dplyr
risk_scores_df <- map(risk_scores, "probabilities") %>%
  bind_cols() %>%
  setNames(names(responses))

variance_df <- map(risk_scores, "variance") %>%
  bind_cols() %>%
  setNames(names(responses))

# Save results
write.csv(risk_scores_df, 
          "./individual stats/probability_senior.csv", 
          row.names = FALSE)
write.csv(variance_df, 
          "./individual stats/probability_variance_senior.csv", 
          row.names = FALSE)

```


```{r identify comorbid pairs}
# Function to calculate pair statistics
calculate_pair_statistics <- function(pair) {
  disease1 <- pair[1]
  disease2 <- pair[2]
  
  test_value <- sum(data[[disease1]] & data[[disease2]])
  
  risk1 <- risk_scores_df[[disease1]]
  risk2 <- risk_scores_df[[disease2]]
  var1 <- variance_df[[disease1]]
  var2 <- variance_df[[disease2]]
  
  expected_value <- sum(risk1 * risk2)
  unadjusted_var <- sum(risk1 * risk2 * (1 - risk1 * risk2))
  adjusted_var <- sum(var1 * risk2^2 + var2 * risk1^2 + var1 * var2)
  final_var <- unadjusted_var + adjusted_var
  
  z_score <- (test_value - expected_value) / sqrt(final_var)
  p_value <- 1 - pnorm(z_score)
  
  c(Disease1 = disease1,
    Disease2 = disease2,
    TestValue = test_value, 
    ExpectedValue = expected_value, 
    UnadjustedVariance = unadjusted_var,
    AdjustedVariance = adjusted_var, 
    FinalVariance = final_var, 
    PValue = p_value)
}

# Generate all pairs and calculate statistics in parallel
network_attributes <- future_map(
  combn(names(responses), 2, simplify = FALSE),
  calculate_pair_statistics,
  .options = furrr_options(seed = TRUE)
)

# Create network dataframe
network_df <- do.call(rbind, network_attributes) %>% 
  as.data.frame() %>%
  mutate(across(TestValue:PValue, as.numeric))

# Apply multiple testing correction
network_df$AdjustedPValue <- p.adjust(network_df$PValue, method = "bonferroni")

# Save all pairs with variances
write.csv(network_df, "./pair stats/all_pairs_variances_senior.csv")

# Filter significant pairs
significant_pairs <- network_df %>% 
  filter(AdjustedPValue < 0.001) %>%
  arrange(AdjustedPValue)

formatted_significant_pairs <- significant_pairs %>%
  transmute(
    Disease1 = map_chr(Disease1, clean_disease_name),
    Disease2 = map_chr(Disease2, clean_disease_name)
  )

# Save results
write.csv(significant_pairs, 
          "./pair stats/significant_pairs_senior.csv", 
          row.names = FALSE)
write_xlsx(formatted_significant_pairs, 
           "./Cytoscape inputs/formatted_pairs_senior.xlsx")
```

```{r reference tables}
# Create final reference table with p-values
reference_table <- formatted_significant_pairs %>%
  mutate(
    Disease1 = as.character(Disease1),
    Disease2 = as.character(Disease2)
  ) %>%
  # Create clean disease lookup to match our codes
  left_join(
    disease_frequencies %>%
      mutate(code = as.character(Numerical.Codes)) %>%
      dplyr::select(code, Disease.Name),  
    by = c("Disease1" = "code")
  ) %>%
  rename(Disease1_name = Disease.Name) %>%
  left_join(
    disease_frequencies %>%
      mutate(code = as.character(Numerical.Codes)) %>%
      dplyr::select(code, Disease.Name),
    by = c("Disease2" = "code")
  ) %>%
  rename(Disease2_name = Disease.Name) %>%
  dplyr::select(Disease1, Disease1_name, Disease2, Disease2_name) %>%  # Explicitly use dplyr::select
  cbind(pval = significant_pairs$AdjustedPValue)

write.csv(reference_table, 
          "./reference tables/reference_senior.csv", 
          row.names = FALSE)

# Create comprehensive table with all statistics
comprehensive_table <- network_df %>%
  mutate(
    Disease1_key = sapply(Disease1, clean_disease_name),
    Disease2_key = sapply(Disease2, clean_disease_name)
  ) %>%
  # Join with disease frequencies for names
  left_join(
    disease_frequencies %>%
      mutate(code = as.character(Numerical.Codes)) %>%
      dplyr::select(code, Disease.Name),
    by = c("Disease1_key" = "code")
  ) %>%
  rename(Disease1_name = Disease.Name) %>%
  left_join(
    disease_frequencies %>%
      mutate(code = as.character(Numerical.Codes)) %>%
      dplyr::select(code, Disease.Name),
    by = c("Disease2_key" = "code")
  ) %>%
  rename(Disease2_name = Disease.Name) %>%
  dplyr::select(
    Disease1, Disease1_key, Disease1_name,
    Disease2, Disease2_key, Disease2_name,
    TestValue, ExpectedValue, 
    UnadjustedVariance, AdjustedVariance, FinalVariance,
    PValue, AdjustedPValue
  ) %>%
  arrange(AdjustedPValue)

write.csv(comprehensive_table, 
          "./pair stats/comprehensive_pairs_senior.csv", 
          row.names = FALSE)
```



