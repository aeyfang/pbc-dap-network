---
title: "result_analysis"
author: "Antoinette Fang"
date: "2024-08-23"
output: html_document
---

```{r setup}
# Load required packages for network analysis and statistical computations
library(tidyverse)    # Data manipulation and analysis
library(readxl)       # Read Excel files
library(poweRlaw)     # Power law distribution fitting
library(fitdistrplus) # Distribution fitting
library(igraph)       # Network analysis and topology metrics
library(caret)        # Statistical modeling functions
library(moments)      # For skewness calculation

# Create necessary directories if they don't exist
dir.create("./figures", showWarnings = FALSE)
dir.create("./additional stats", showWarnings = FALSE)
dir.create("./network tables", showWarnings = FALSE)
```

```{r data loading}
# Load previously processed data files for analysis
# Demographic data files
cleaned_without_healthy_dogs <- read.csv(file = "./clean data/cleaned_unstrat.csv")
cleaned_with_healthy_dogs <- read.csv(file="./clean data/merged_data_with_healthy_dogs.csv")
disease_frequencies <- read.csv(file = "./frequency tables/disease_frequencies_unstrat.csv")

# Network data files - pairs of comorbid conditions from different age strata
senior_pairs <- read.csv("./pair stats/significant_pairs_senior.csv", stringsAsFactors=FALSE) %>%
  mutate(age_group = "senior")
mature_adult_pairs <- read.csv("./pair stats/significant_pairs_mature_adult.csv", stringsAsFactors=FALSE) %>%
  mutate(age_group = "mature_adult")
young_adult_pairs <- read.csv("./pair stats/significant_pairs_young_adult.csv", stringsAsFactors=FALSE) %>%
  mutate(age_group = "young_adult")
puppy_pairs <- read.csv("./pair stats/significant_pairs_puppy.csv", stringsAsFactors=FALSE) %>%
  mutate(age_group = "puppy")
unstrat_pairs <- read.csv("./pair stats/significant_pairs_unstrat.csv", stringsAsFactors=FALSE) %>%
  mutate(age_group = "unstratified")
frequency<-read.csv("./frequency tables/disease_frequencies_unstrat.csv")
```

```{r network edge standardization}
# Standardize edge representation across all networks for comparison
# Create consistent edge IDs by sorting disease pairs alphabetically

# Function to convert disease codes to numerical codes using frequency table
get_numerical_code <- function(disease_code) {
  # Handle condition_ codes
  if(startsWith(disease_code, "condition_")) {
    return(as.numeric(sub("^condition_", "", disease_code)))
  }
  
  # Handle hs_cancer_types_ codes using frequency table lookup
  if(startsWith(disease_code, "hs_cancer_types_")) {
    match_row <- disease_frequencies[disease_frequencies$Code.from.DAP.data == disease_code, ]
    if(nrow(match_row) > 0) {
      return(as.numeric(match_row$Numerical.Codes))
    }
  }
  
  # Return NA if no match found
  return(NA)
}

# Function to process pairs and create standardized edge identifiers
process_pairs <- function(df) {
  df %>%
    mutate(
      code1 = sapply(Disease1, get_numerical_code),
      code2 = sapply(Disease2, get_numerical_code),
      code_left = pmin(code1, code2, na.rm = TRUE),
      code_right = pmax(code1, code2, na.rm = TRUE),
      sorted_pair = paste(code_left, code_right, sep = "-")
    ) %>%
    # Remove any rows where we couldn't get numerical codes
    filter(!is.na(code1) & !is.na(code2)) %>%
    pull(sorted_pair)
}

# Process each dataset to extract standardized edge information
senior_edges <- process_pairs(senior_pairs)
mature_edges <- process_pairs(mature_adult_pairs)
young_edges <- process_pairs(young_adult_pairs)
puppy_edges <- process_pairs(puppy_pairs)
unstrat_edges <- process_pairs(unstrat_pairs)

# Create named list of all edge sets for analysis
all_edge_sets <- list(
  unstratified = unstrat_edges,
  puppy = puppy_edges,
  young_adult = young_edges,
  mature_adult = mature_edges,
  senior = senior_edges
)

cat("Edge sets processed:",
    "\nUnstratified:", length(unstrat_edges), "edges",
    "\nPuppy:", length(puppy_edges), "edges", 
    "\nYoung adult:", length(young_edges), "edges",
    "\nMature adult:", length(mature_edges), "edges",
    "\nSenior:", length(senior_edges), "edges\n")
```

```{r network overlap analysis}
# Calculate pairwise overlap between all network edge sets
# This quantifies how many edges are shared between different age groups

# Create overlap matrix to quantify shared edges between networks
n_sets <- length(all_edge_sets)
overlap_matrix <- matrix(0, nrow = n_sets, ncol = n_sets)
rownames(overlap_matrix) <- colnames(overlap_matrix) <- names(all_edge_sets)

# Calculate overlaps - pairwise comparisons of edge sets
for(i in 1:n_sets) {
  for(j in i:n_sets) {
    overlap <- length(intersect(all_edge_sets[[i]], all_edge_sets[[j]]))
    overlap_matrix[i,j] <- overlap
    overlap_matrix[j,i] <- overlap
  }
}

# Convert matrix to long format for analysis and save
overlap_df <- as.data.frame(overlap_matrix) %>%
  mutate(category = rownames(overlap_matrix)) %>%
  pivot_longer(
    cols = -category,
    names_to = "comparison",
    values_to = "shared_edges"
  )

# Define order for visualization
desired_order <- c("unstratified", "puppy", "young_adult", "mature_adult", "senior")

# Create heatmap visualization of edge overlap
overlap_heatmap <- overlap_df %>%
  mutate(
    category = factor(category, levels = desired_order),
    comparison = factor(comparison, levels = desired_order)
  ) %>%
  filter(as.numeric(category) <= as.numeric(comparison)) %>%
  ggplot(aes(x = category, y = comparison, fill = shared_edges)) +
  geom_tile(color = "black", linewidth = 0.5) +
  geom_text(aes(label = shared_edges), color = "black", size = 4) +
  scale_fill_gradient(low = "#ffffff", high = "#00abc8") +
  theme_minimal() +
  labs(fill = "Shared Edges") +
  theme(
    axis.text.x.top = element_text(angle = 45, hjust = 0, size = 12),
    axis.text.y = element_text(hjust = 1, size = 12),
    axis.title = element_blank(),
    axis.title.x.top = element_blank(),
    axis.ticks.x.top = element_line(),
    axis.ticks.x.bottom = element_blank(),
    axis.ticks.y = element_blank(),
    legend.title = element_text(size = 10),
    legend.text = element_text(size = 10),
    panel.grid = element_blank(),
    aspect.ratio = 1
  ) +
  scale_x_discrete(
    limits = desired_order,
    position = "top",
    labels = c("unstratified", "puppy", "young adult", "mature adult", "senior")
  ) +
  scale_y_discrete(
    limits = rev(desired_order),
    labels = rev(c("unstratified", "puppy", "young adult", "mature adult", "senior"))
  ) +
  coord_fixed()

print(overlap_heatmap)

# Save network overlap heatmap
ggsave("./figures/network_overlap_heatmap.tiff", overlap_heatmap, 
       width = 8, height = 6, dpi = 600, compression = "lzw")

ggsave("./figures/network_overlap_heatmap.png", overlap_heatmap, 
       width = 8, height = 6, dpi = 600)

# Save overlap matrix for visualization
write.csv(overlap_matrix, "./network tables/network_overlap_matrix.csv", row.names = TRUE)
write.csv(overlap_df, "./network tables/network_overlap_long.csv", row.names = FALSE)
```

```{r shared comorbidities across age groups}
# Identify edges present across multiple age-stratified networks
# Find core comorbidity relationships that persist across life stages

# Find edges present in all age-stratified networks (excluding unstratified)
shared_edges_all_ages <- Reduce(intersect, list(
  young_edges,
  mature_edges,
  senior_edges
))

# Calculate edge counts and percentages for each network
edge_counts <- list(
  "Unstratified" = length(unstrat_edges),
  "Puppy" = length(puppy_edges),
  "Young Adult" = length(young_edges),
  "Mature Adult" = length(mature_edges),
  "Senior" = length(senior_edges)
)

# Calculate what percentage of each network consists of shared edges
percentages_shared <- sapply(edge_counts, function(x) {
  if(x > 0) round(length(shared_edges_all_ages) / x * 100, 1) else 0
})

# Create summary data frame
shared_edges_summary <- data.frame(
  Network = names(edge_counts),
  Total_Edges = unlist(edge_counts),
  Shared_Edges = length(shared_edges_all_ages),
  Percent_Shared = percentages_shared
)

# Find unique edges for each age group (compared to unstratified)
young_adult_unique <- setdiff(young_edges, unstrat_edges)
mature_adult_unique <- setdiff(mature_edges, unstrat_edges)
senior_unique <- setdiff(senior_edges, unstrat_edges)

# Calculate overlap between age-specific unique edges
age_unique_overlaps <- list(
  young_mature_shared = intersect(young_adult_unique, mature_adult_unique),
  young_senior_shared = intersect(young_adult_unique, senior_unique),
  mature_senior_shared = intersect(mature_adult_unique, senior_unique),
  all_age_shared = Reduce(intersect, list(young_adult_unique, mature_adult_unique, senior_unique))
)

# Create comprehensive summary statistics
age_specific_summary <- data.frame(
  Age_Group = c("Young Adult", "Mature Adult", "Senior"),
  Total_Edges = c(length(young_edges), length(mature_edges), length(senior_edges)),
  Unique_Edges = c(length(young_adult_unique), length(mature_adult_unique), length(senior_unique)),
  Percent_Unique = c(
    round(length(young_adult_unique) / length(young_edges) * 100, 1),
    round(length(mature_adult_unique) / length(mature_edges) * 100, 1),
    round(length(senior_unique) / length(senior_edges) * 100, 1)
  )
)

# Save results
write.csv(shared_edges_summary, "./additional stats/shared_edges_summary.csv", row.names = FALSE)
write.csv(age_specific_summary, "./additional stats/age_specific_summary.csv", row.names = FALSE)

# Print key findings
cat("Shared comorbidities analysis:",
    "\nEdges shared across all age groups:", length(shared_edges_all_ages),
    "\nEdges unique to individual age groups:", sum(age_specific_summary$Unique_Edges),
    "\nEdges shared between young-mature only:", length(age_unique_overlaps$young_mature_shared),
    "\nEdges shared between mature-senior only:", length(age_unique_overlaps$mature_senior_shared), "\n")
```
```{r age group specific edges}
# Identify edges that are unique to specific age combinations
# This helps understand developmental patterns in comorbidity

# Compute age group-specific edges (exclusive to each group vs others)
senior_specific_edges <- setdiff(senior_edges, union(mature_edges, young_edges))
mature_specific_edges <- setdiff(mature_edges, union(senior_edges, young_edges))
young_specific_edges <- setdiff(young_edges, union(senior_edges, mature_edges))

# Function to extract unique node IDs from edge strings
extract_nodes <- function(edge_vector) {
  unique(unlist(strsplit(edge_vector, "-")))
}

# Get unique nodes from each age-specific edge group
senior_unique_nodes <- extract_nodes(senior_specific_edges)
mature_unique_nodes <- extract_nodes(mature_specific_edges)
young_unique_nodes <- extract_nodes(young_specific_edges)

# Create detailed edge tables with disease names and categories
lookup_table <- disease_frequencies %>%
  dplyr::select(Code.from.DAP.data, Disease.Name, Disease.Category) %>%
  mutate(Code.from.DAP.data = as.character(Code.from.DAP.data))

# Lookup functions for disease information
lookup_disease_name <- function(code_number) {
  match <- lookup_table$Disease.Name[lookup_table$Code.from.DAP.data == as.character(code_number)]
  if (length(match) == 1) return(match)
  return(NA)
}

lookup_disease_category <- function(code_number) {
  match <- lookup_table$Disease.Category[lookup_table$Code.from.DAP.data == as.character(code_number)]
  if (length(match) == 1) return(match)
  return(NA)
}

# Build detailed edge tables for each age group
build_edge_table <- function(edge_vector, age_group_name) {
  if(length(edge_vector) == 0) {
    return(data.frame(
      age_group = character(),
      disease_1 = character(),
      category_1 = character(),
      disease_2 = character(),
      category_2 = character(),
      in_unstratified = character()
    ))
  }
  
  tibble(edge = edge_vector) %>%
    separate(edge, into = c("code1", "code2"), sep = "-", convert = TRUE) %>%
    mutate(
      age_group = age_group_name,
      disease_1 = sapply(code1, lookup_disease_name),
      category_1 = sapply(code1, lookup_disease_category),
      disease_2 = sapply(code2, lookup_disease_name),
      category_2 = sapply(code2, lookup_disease_category),
      in_unstratified = ifelse(
        paste(code1, code2, sep = "-") %in% unstrat_edges |
        paste(code2, code1, sep = "-") %in% unstrat_edges,
        "Yes", "No"
      )
    ) %>%
    dplyr::select(age_group, disease_1, category_1, disease_2, category_2, in_unstratified)
}

# Create detailed tables for each age group
senior_edge_table <- build_edge_table(senior_specific_edges, "Senior")
mature_edge_table <- build_edge_table(mature_specific_edges, "Mature Adult")
young_edge_table <- build_edge_table(young_specific_edges, "Young Adult")

# Combine all age-specific edge tables
all_age_specific_edges <- bind_rows(senior_edge_table, mature_edge_table, young_edge_table)

# Save detailed edge tables
write.csv(senior_edge_table, "./additional stats/senior_specific_edges_with_categories.csv", row.names = FALSE)
write.csv(mature_edge_table, "./additional stats/mature_specific_edges_with_categories.csv", row.names = FALSE)
write.csv(young_edge_table, "./additional stats/young_specific_edges_with_categories.csv", row.names = FALSE)
write.csv(all_age_specific_edges, "./additional stats/all_age_specific_edges.csv", row.names = FALSE)

# Print summary
cat("Age-specific edge analysis:",
    "\nSenior-specific edges:", length(senior_specific_edges),
    "\nMature adult-specific edges:", length(mature_specific_edges),
    "\nYoung adult-specific edges:", length(young_specific_edges), "\n")
```
```{r unstratified unique edges}
# Identify edges that appear only in the unstratified network
# These may represent associations diluted by age stratification

# Combine all stratified network edges
all_stratified_edges <- unique(c(young_edges, mature_edges, senior_edges, puppy_edges))

# Find edges unique to the unstratified network
unique_unstrat_edges <- setdiff(unstrat_edges, all_stratified_edges)

# Calculate summary statistics
n_unique_unstrat <- length(unique_unstrat_edges)
percent_unique_unstrat <- round((n_unique_unstrat / length(unstrat_edges)) * 100, 1)

# Create unstratified-specific edge table
unstrat_edge_table <- build_edge_table(unique_unstrat_edges, "Unstratified Only")

# Save unstratified-specific analysis
write.csv(unstrat_edge_table, "./additional stats/unstratified_specific_edges.csv", row.names = FALSE)

# Create comprehensive summary of all unique edge patterns
edge_pattern_summary <- data.frame(
  Pattern = c("Shared across all age groups", "Senior-specific", "Mature-specific", 
              "Young-specific", "Unstratified-specific"),
  Count = c(length(shared_edges_all_ages), length(senior_specific_edges),
            length(mature_specific_edges), length(young_specific_edges), 
            n_unique_unstrat),
  Percent_of_Unstratified = c(
    round(length(shared_edges_all_ages) / length(unstrat_edges) * 100, 1),
    round(length(senior_specific_edges) / length(unstrat_edges) * 100, 1),
    round(length(mature_specific_edges) / length(unstrat_edges) * 100, 1),
    round(length(young_specific_edges) / length(unstrat_edges) * 100, 1),
    percent_unique_unstrat
  )
)

write.csv(edge_pattern_summary, "./additional stats/edge_pattern_summary.csv", row.names = FALSE)

cat("Unstratified network analysis:",
    "\nTotal edges in unstratified network:", length(unstrat_edges),
    "\nEdges unique to unstratified network:", n_unique_unstrat,
    "\nPercentage unique to unstratified:", percent_unique_unstrat, "%\n")
```
```{r calculate node degrees}
# Calculate node degrees organically from the unstratified network
# This provides the degree distribution for statistical analysis

# Create graph from unstratified significant pairs
unstrat_graph <- graph_from_data_frame(
  unstrat_pairs %>% dplyr::select(Disease1, Disease2), 
  directed = FALSE
)

# Remove isolated vertices (nodes with no connections)
unstrat_graph <- delete_vertices(unstrat_graph, degree(unstrat_graph) == 0)

# Calculate degree for each node
node_degrees <- degree(unstrat_graph)
node_data <- as.numeric(node_degrees)

# Create comprehensive node degree table with disease information
node_degree_table <- data.frame(
  disease_code = names(node_degrees),
  degree = node_degrees,
  stringsAsFactors = FALSE
) %>%
  mutate(
    # Clean disease codes for matching
    clean_code = sub("^condition_", "", disease_code),
    # Add disease names and categories
    disease_name = sapply(clean_code, function(code) {
      if(code %in% disease_frequencies$Code.from.DAP.data) {
        return(disease_frequencies$Disease.Name[disease_frequencies$Code.from.DAP.data == code])
      } else if(code %in% disease_frequencies$Numerical.Codes) {
        return(disease_frequencies$Disease.Name[disease_frequencies$Numerical.Codes == as.numeric(code)])
      }
      return(NA)
    }),
    disease_category = sapply(clean_code, function(code) {
      if(code %in% disease_frequencies$Code.from.DAP.data) {
        return(disease_frequencies$Disease.Category[disease_frequencies$Code.from.DAP.data == code])
      } else if(code %in% disease_frequencies$Numerical.Codes) {
        return(disease_frequencies$Disease.Category[disease_frequencies$Numerical.Codes == as.numeric(code)])
      }
      return(NA)
    })
  ) %>%
  arrange(desc(degree))

# Save node degree analysis
write.csv(node_degree_table, "./additional stats/node_degrees_unstratified.csv", row.names = FALSE)

cat("Node degree calculation:",
    "\nTotal nodes in unstratified network:", length(node_data),
    "\nNodes with degree > 0:", sum(node_data > 0),
    "\nMaximum degree:", max(node_data),
    "\nMean degree:", round(mean(node_data), 2), "\n")
```
```{r analyze degree distribution}
# Test whether it follows power law or exponential distribution

# Fit power law distribution
power_fit <- displ$new(node_data)
power_fit$setPars(estimate_pars(power_fit))

# Fit exponential distribution
exp_fit <- disexp$new(node_data)
exp_fit$setPars(estimate_pars(exp_fit))
exp_params <- fitdistr(node_data, 'exponential')

# Compare distributions statistically
power_vs_exp <- compare_distributions(power_fit, exp_fit)
exp_vs_power <- compare_distributions(exp_fit, power_fit)

# Create degree frequency table for visualization
degree_freq <- as.data.frame(table(node_data)) %>%
  mutate(
    degrees = as.numeric(as.character(node_data)),
    Frequency = Freq / sum(Freq),
    Cumulative_Freq = cumsum(Frequency)
  ) %>%
  dplyr::select(degrees, Frequency, Cumulative_Freq, Count = Freq)

# Generate distribution curves for plotting
x_values <- seq(1, max(node_data), length.out = 1000)

curves <- rbind(
  # Exponential curve
  data.frame(
    X = x_values,
    estimate = dexp(x_values, rate = exp_params$estimate),
    category = "Exponential"
  ),
  # Power law curve
  data.frame(
    X = x_values,
    estimate = (x_values^(-power_fit$pars)) / sum((power_fit$xmin:max(node_data))^(-power_fit$pars)),
    category = "Power Law"
  )
)

# Create visualization of degree distribution with fitted curves
distribution_plot <- ggplot() +
  geom_point(data = degree_freq, 
             aes(x = degrees, y = Frequency), 
             size = 3) +
  geom_line(data = curves, 
            aes(x = X, y = estimate, colour = category),
            size = 1.5) +
  scale_color_manual(values = c("#1B365D", "#00ABC8")) +
  scale_x_continuous(breaks = seq(0, max(node_data), by = 1)) +
  scale_y_log10(
    breaks = c(0.001, 0.01, 0.1, 1),
    labels = c("0.001", "0.01", "0.1", "1")
  ) +
  labs(x = "Degree",
       y = "log(Density)",
       color = "Model") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "right",
    axis.text.x = element_text(hjust = 1),
    axis.title = element_text(size = 24, face = "bold"),
    axis.text = element_text(size = 18),
    legend.title = element_text(size = 18),
    legend.text = element_text(size = 16),
    panel.grid.minor = element_blank()
  )

print(distribution_plot)

# Save degree distribution plot
ggsave(filename = "./figures/degree_distribution_analysis.tiff", 
       plot = distribution_plot,
       width = 8, 
       height = 5, 
       dpi = 600,
       compression = "lzw")

ggsave(filename = "./figures/degree_distribution_analysis.png", 
       plot = distribution_plot,
       width = 8, 
       height = 5, 
       dpi = 600)

# Generate distribution parameters and goodness-of-fit statistics
distribution_results <- data.frame(
  Distribution = c("Power Law", "Exponential"),
  Parameter = c(power_fit$pars, exp_params$estimate),
  Parameter_Name = c("Alpha", "Rate"),
  LogLikelihood = c(
    dist_ll(power_fit),
    sum(dexp(node_data, rate = exp_params$estimate, log = TRUE))
  ),
  P_Value_vs_Other = c(power_vs_exp$p_two_sided, exp_vs_power$p_one_sided)
) %>%
  mutate(
    AIC = -2 * LogLikelihood + 2 * c(1, 1)  # Both distributions have 1 parameter
  )

# Save degree distribution analysis
write.csv(degree_freq, "./additional stats/degree_frequency_table.csv", row.names = FALSE)
write.csv(distribution_results, "./additional stats/distribution_comparison.csv", row.names = FALSE)

# Create summary statistics for degree distribution
degree_stats <- data.frame(
  Statistic = c("Mean", "Median", "Standard Deviation", "Min", "Max", "Skewness"),
  Value = c(
    mean(node_data),
    median(node_data),
    sd(node_data),
    min(node_data),
    max(node_data),
    moments::skewness(node_data)
  )
)

write.csv(degree_stats, "./additional stats/degree_distribution_stats.csv", row.names = FALSE)

# Print statistical results
cat("Degree Distribution Analysis:",
    "\nNumber of nodes analyzed:", length(node_data),
    "\nMean degree:", round(mean(node_data), 2),
    "\nPower law alpha:", round(power_fit$pars, 3),
    "\nExponential rate:", round(exp_params$estimate, 3),
    "\nP-value (Exp vs Power):", round(exp_vs_power$p_one_sided, 4), "\n")

# Determine best-fitting distribution
if(exp_vs_power$p_one_sided < 0.05) {
  best_fit <- "Exponential distribution provides significantly better fit"
} else if(power_vs_exp$p_two_sided < 0.05) {
  best_fit <- "Power law distribution provides significantly better fit"
} else {
  best_fit <- "No significant difference between distributions"
}

cat("Best fitting distribution:", best_fit, "\n")
```
```{r network topology metrics}
# Calculate comprehensive network topology metrics for each age group
# This includes centrality measures, clustering, and structural properties

# Helper function to format edge data for igraph
format_edges_for_igraph <- function(pair_table) {
  pair_table %>%
    dplyr::select(Disease1, Disease2) %>%
    {c(t(.))}
}

# Function to calculate comprehensive network metrics
calculate_network_metrics <- function(pair_table, network_name) {
  # Create graph object
  edge_vector <- format_edges_for_igraph(pair_table)
  graph <- make_graph(edges = edge_vector, directed = FALSE)
  
  # Remove isolated vertices
  graph <- delete_vertices(graph, degree(graph) == 0)
  
  # Get largest connected component
  largest_comp <- largest_component(graph)
  
  # Calculate metrics for full graph
  full_metrics <- list(
    network = network_name,
    component = "full",
    nodes = vcount(graph),
    edges = ecount(graph),
    edge_density = edge_density(graph, loops = FALSE),
    clustering_coefficient = transitivity(graph, type = "global"),
    degree_centralization = centr_degree(graph, mode = "all", loops = FALSE, normalized = TRUE)$centralization,
    betweenness_centralization = centr_betw(graph, directed = FALSE, normalized = TRUE)$centralization,
    closeness_centralization = centr_clo(graph, mode = "all", normalized = TRUE)$centralization,
    connected_components = components(graph)$no,
    largest_component_size = vcount(largest_comp),
    average_path_length = ifelse(is_connected(graph), mean_distance(graph), NA),
    diameter = ifelse(is_connected(graph), diameter(graph), NA)
  )
  
  # Calculate metrics for largest connected component
  lcc_metrics <- list(
    network = network_name,
    component = "largest_connected",
    nodes = vcount(largest_comp),
    edges = ecount(largest_comp),
    edge_density = edge_density(largest_comp, loops = FALSE),
    clustering_coefficient = transitivity(largest_comp, type = "global"),
    degree_centralization = centr_degree(largest_comp, mode = "all", loops = FALSE, normalized = TRUE)$centralization,
    betweenness_centralization = centr_betw(largest_comp, directed = FALSE, normalized = TRUE)$centralization,
    closeness_centralization = centr_clo(largest_comp, mode = "all", normalized = TRUE)$centralization,
    connected_components = 1,
    largest_component_size = vcount(largest_comp),
    average_path_length = mean_distance(largest_comp),
    diameter = diameter(largest_comp)
  )
  
  return(bind_rows(full_metrics, lcc_metrics))
}

# Calculate metrics for all networks
network_metrics_list <- list(
  calculate_network_metrics(unstrat_pairs, "unstratified"),
  calculate_network_metrics(puppy_pairs, "puppy"),
  calculate_network_metrics(young_adult_pairs, "young_adult"),
  calculate_network_metrics(mature_adult_pairs, "mature_adult"),
  calculate_network_metrics(senior_pairs, "senior")
)

# Combine all metrics into single dataframe
all_network_metrics <- bind_rows(network_metrics_list)

# Save comprehensive network topology results
write.csv(all_network_metrics, "./additional stats/network_topology_metrics.csv", row.names = FALSE)

# Create summary comparison table (full networks only)
topology_summary <- all_network_metrics %>%
  filter(component == "full") %>%
  dplyr::select(network, nodes, edges, edge_density, clustering_coefficient, 
         degree_centralization, betweenness_centralization) %>%
  arrange(desc(nodes))

write.csv(topology_summary, "./network tables/topology_summary.csv", row.names = FALSE)

cat("Network topology analysis completed for", length(network_metrics_list), "age groups\n")
cat("Metrics calculated: density, clustering, centralization, path length, diameter\n")
```

```{r breed disease association analysis}
# Comprehensive analysis of disease prevalence by breed background
# Compare purebred vs. mixed breed dogs using logistic regression

# Prepare dataset for breed analysis
diseases_data <- cleaned_with_healthy_dogs %>%
  mutate(
    # Create factors and derived variables
    purebred = factor(dd_breed_pure > 0, labels = c("Mixed", "Pure")),
    age = as.numeric(dd_age_years),
    weight = as.numeric(dd_weight_lbs),
    sex_2 = as.numeric(recode.sex_2),
    sex_3 = as.numeric(recode.sex_3),
    sex_4 = as.numeric(recode.sex_4)
  )

# Create reference table for disease code lookup
reference_table <- disease_frequencies %>%
  dplyr::select(Code.from.DAP.data, Disease.Name) %>%
  mutate(Code.from.DAP.data = as.character(Code.from.DAP.data))

# Define all disease columns for analysis
all_disease_columns <- c(
  "hs_cancer_types_mast_cell_tumor",
  paste0("condition_", reference_table$Code.from.DAP.data[
    reference_table$Code.from.DAP.data != "hs_cancer_types_mast_cell_tumor"
  ])
)

# Function to fit breed comparison model and extract results
fit_breed_model <- function(disease, data) {
  # Skip if disease column doesn't exist in data
  if(!(disease %in% names(data))) return(NULL)
  
  # Fit logistic regression with breed as predictor, adjusting for covariates
  formula <- as.formula(paste(disease, "~ purebred + age + weight + sex_2 + sex_3 + sex_4"))
  
  tryCatch({
    model <- glm(formula, family = binomial(link = "logit"), data = data)
    
    # Extract results for purebred coefficient
    coef_summary <- summary(model)$coefficients
    if(!"purebredPure" %in% rownames(coef_summary)) return(NULL)
    
    coef <- coef_summary["purebredPure", ]
    odds_ratio <- exp(coef["Estimate"])
    ci <- exp(coef["Estimate"] + c(-1, 1) * 1.96 * coef["Std. Error"])
    
    # Calculate prevalence by breed type
    prev_mixed <- mean(data[data$purebred == "Mixed", disease], na.rm = TRUE)
    prev_pure <- mean(data[data$purebred == "Pure", disease], na.rm = TRUE)
    
    # Return formatted results
    return(data.frame(
      Disease = disease,
      Estimate = coef["Estimate"],
      StdError = coef["Std. Error"],
      OddsRatio = odds_ratio,
      CI_Lower = ci[1],
      CI_Upper = ci[2],
      P_Value = coef["Pr(>|z|)"],
      Prevalence_Mixed = prev_mixed,
      Prevalence_Pure = prev_pure,
      stringsAsFactors = FALSE
    ))
  }, error = function(e) {
    warning(paste("Model failed for disease:", disease, "- Error:", e$message))
    return(NULL)
  })
}

# Run logistic regression models for each disease
breed_results <- map_dfr(all_disease_columns, ~fit_breed_model(.x, diseases_data))

# Apply multiple testing correction
breed_results$P_Adjusted <- p.adjust(breed_results$P_Value, method = "BH")

# Format disease names using reference table
breed_results_formatted <- breed_results %>%
  mutate(
    Disease_Name = sapply(Disease, function(d) {
      if(grepl("condition_", d)) {
        code <- sub("condition_", "", d)
        match <- reference_table$Disease.Name[reference_table$Code.from.DAP.data == code]
        if(length(match) > 0) return(match)
      }
      if(grepl("hs_cancer_types_", d)) {
        return("Mast cell tumor")
      }
      return(d)
    }),
    Risk_Category = case_when(
      P_Adjusted < 0.05 & OddsRatio > 1 ~ "Higher risk in purebred",
      P_Adjusted < 0.05 & OddsRatio < 1 ~ "Higher risk in mixed breed",
      TRUE ~ "No significant difference"
    ),
    Effect_Size = abs(log(OddsRatio))
  ) %>%
  arrange(P_Adjusted)

# Save comprehensive breed analysis results
write.csv(breed_results_formatted, "./additional stats/breed_disease_associations_full.csv", row.names = FALSE)

# Create summary statistics by risk category
breed_risk_summary <- breed_results_formatted %>%
  count(Risk_Category) %>%
  mutate(Percentage = round(n / sum(n) * 100, 1))

write.csv(breed_risk_summary, "./additional stats/breed_risk_summary.csv", row.names = FALSE)

# Identify top diseases with strongest breed associations
top_purebred_risk <- breed_results_formatted %>%
  filter(Risk_Category == "Higher risk in purebred") %>%
  arrange(desc(OddsRatio)) %>%
  head(10) %>%
  dplyr::select(Disease_Name, OddsRatio, CI_Lower, CI_Upper, P_Adjusted)

top_mixed_risk <- breed_results_formatted %>%
  filter(Risk_Category == "Higher risk in mixed breed") %>%
  arrange(OddsRatio) %>%
  head(10) %>%
  dplyr::select(Disease_Name, OddsRatio, CI_Lower, CI_Upper, P_Adjusted)

# Save top associations
write.csv(top_purebred_risk, "./additional stats/top_purebred_risk_diseases.csv", row.names = FALSE)
write.csv(top_mixed_risk, "./additional stats/top_mixed_risk_diseases.csv", row.names = FALSE)

# Print summary results
cat("Breed-disease association analysis:",
    "\nTotal diseases analyzed:", nrow(breed_results_formatted),
    "\nDiseases with higher risk in purebred dogs:", sum(breed_results_formatted$Risk_Category == "Higher risk in purebred"),
    "\nDiseases with higher risk in mixed breed dogs:", sum(breed_results_formatted$Risk_Category == "Higher risk in mixed breed"),
    "\nDiseases with no significant difference:", sum(breed_results_formatted$Risk_Category == "No significant difference"), "\n")
```
```{r save analysis summary}
# Create comprehensive summary of all analyses performed
analysis_summary <- data.frame(
  Analysis = c(
    "Network Overlap Analysis",
    "Shared Comorbidities Across Ages", 
    "Age-Specific Edge Patterns",
    "Degree Distribution Fitting",
    "Network Topology Metrics",
    "Breed-Disease Associations"
  ),
  Description = c(
    "Pairwise overlap between all age-stratified networks",
    "Edges present across young adult, mature adult, and senior networks",
    "Edges unique to specific age groups vs. others",
    "Power law vs. exponential distribution comparison for node degrees",
    "Centrality, clustering, and structural metrics for all networks",
    "Logistic regression comparing disease risk in purebred vs. mixed breed dogs"
  ),
  Key_Findings = c(
    paste("Maximum overlap:", max(overlap_matrix[upper.tri(overlap_matrix)]), "edges"),
    paste("Shared across all ages:", length(shared_edges_all_ages), "edges"),
    paste("Total age-specific edges:", sum(age_specific_summary$Unique_Edges)),
    paste("Best fit:", ifelse(exp_vs_power$p_one_sided < 0.05, "Exponential", "Neither")),
    paste("Networks analyzed:", nrow(topology_summary)),
    paste("Significant associations:", sum(breed_results_formatted$P_Adjusted < 0.05))
  ),
  Output_Files = c(
    "network_overlap_matrix.csv, network_overlap_long.csv",
    "shared_edges_summary.csv, age_specific_summary.csv", 
    "all_age_specific_edges.csv, edge_pattern_summary.csv",
    "degree_frequency_table.csv, distribution_comparison.csv",
    "network_topology_metrics.csv, topology_summary.csv",
    "breed_disease_associations_full.csv, breed_risk_summary.csv"
  )
)

write.csv(analysis_summary, "./additional stats/analysis_summary.csv", row.names = FALSE)

cat("\n=== ANALYSIS COMPLETE ===")
cat("\nAll analytical computations finished successfully.")
cat("\nResults saved to ./additional stats/ and ./network tables/ directories.")
cat("\nSummary of analyses:", nrow(analysis_summary), "major analytical components completed.\n")
```

